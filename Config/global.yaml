app:
  name: AutoLogic
  version: 0.2.0
  environment: development
  debug: true
llm:
  active_provider: openai
  active_model: gpt-4-turbo
  temperature: 0.5
  max_tokens: 2048
  timeout: 60
  max_retries: 3
  resilience:
    rate_limit: 15.0
    retry_enabled: true
    max_retries: 3
    retry_base_delay: 2.0
    fallback_enabled: true
  providers:
    openrouter:
      enabled: true
      base_url: https://openrouter.ai/api/v1
      default_model: google/gemini-2.0-flash-001
      models:
      - google/gemini-2.0-flash-001
      - meta-llama/llama-3.3-70b-instruct:free
      - anthropic/claude-3-opus
      - anthropic/claude-3-sonnet
      - openai/gpt-4-turbo
      - meta-llama/llama-3-70b-instruct
    openai:
      enabled: true
      base_url: https://api.openai.com/v1
      default_model: gpt-4-turbo
      models:
      - gpt-4-turbo
      - gpt-4o
      - gpt-4o-mini
      - gpt-3.5-turbo
    ollama:
      enabled: true
      base_url: http://localhost:11434
      default_model: llama3
      timeout: 120
      auto_detect_models: true
      models:
      - llama3
      - llama2
      - mistral
      - mixtral
      - gemma
      - phi3
      - codellama
    vllm:
      enabled: false
      default_model: local-model
      auto_detect_models: true
      models: []
    huggingface:
      enabled: true
      base_url: https://api-inference.huggingface.co/models
      default_model: meta-llama/Meta-Llama-3-70B-Instruct
      models:
      - meta-llama/Meta-Llama-3-70B-Instruct
      - mistralai/Mixtral-8x7B-Instruct-v0.1
      - google/gemma-7b
      - microsoft/Phi-3-mini-4k-instruct
  top_p: 1.0
  audit_timeout: 60
  audit_max_retries: 5
  free_only: true
  rate_limit: 15.0
  retry_enabled: true
  fallback_enabled: true
database:
  host: localhost
  port: 5432
  name: autologic_db
vector_store:
  provider: chromadb
  path: ./data/chroma
logging:
  level: INFO
  file: Log/backend_app.log
