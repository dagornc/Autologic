# Architecture du Projet AutoLogic

## Vue d'Ensemble

AutoLogic est un moteur d'inf√©rence cognitif impl√©mentant le **Self-Discovery Reasoning Framework**. L'architecture repose sur une orchestration √† **Triple Agent** (Strategic, Worker, Audit) et un cycle de raisonnement en **8 phases**.

---

## Arborescence du Projet

```
AutoLogic/
‚îú‚îÄ‚îÄ Cmd/                        # Scripts shell standalone
‚îÇ   ‚îú‚îÄ‚îÄ start_backend.sh        # Lance le backend FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ start_frontend.sh       # Lance le frontend React/Vite
‚îÇ   ‚îú‚îÄ‚îÄ run_tests.sh            # Ex√©cute pytest
‚îÇ   ‚îú‚îÄ‚îÄ lint.sh                 # V√©rifie qualit√© code (black, flake8, mypy)
‚îÇ   ‚îî‚îÄ‚îÄ generate_docs.sh        # G√©n√®re la documentation Sphinx
‚îú‚îÄ‚îÄ Code/
‚îÇ   ‚îú‚îÄ‚îÄ Backend/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Phase1-Ingestion/   # Pipeline d'ingestion RAG
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Phase2-Inference/   # Logique de raisonnement
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 01_Reasoning/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ autologic/  # Package principal
‚îÇ   ‚îÇ               ‚îú‚îÄ‚îÄ core/           # Moteur, LLM, Factory, R√©silience
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ engine.py           # AutoLogicEngine - Cycle 8 phases
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ llm_provider.py     # 5 providers LLM
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ provider_factory.py # Factory Pattern
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ resilience.py       # Rate limiter, Retry, Fallback
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ model_registry.py   # Registre des mod√®les
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Mod√®les Pydantic
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py          # Templates de prompts
‚îÇ   ‚îÇ               ‚îÇ   ‚îî‚îÄ‚îÄ critic.py           # Agent Critic H2
‚îÇ   ‚îÇ               ‚îú‚îÄ‚îÄ routers/        # Endpoints FastAPI
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ reasoning.py        # /reason/* endpoints
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ models.py           # /api/* endpoints
‚îÇ   ‚îÇ               ‚îÇ   ‚îú‚îÄ‚îÄ history.py          # Historique des sessions
‚îÇ   ‚îÇ               ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py          # Templates API
‚îÇ   ‚îÇ               ‚îú‚îÄ‚îÄ utils/          # Logging, helpers
‚îÇ   ‚îÇ               ‚îî‚îÄ‚îÄ data/           # Modules de raisonnement JSON
‚îÇ   ‚îî‚îÄ‚îÄ Frontend/               # Application React/Vite
‚îÇ       ‚îî‚îÄ‚îÄ src/
‚îÇ           ‚îú‚îÄ‚îÄ components/     # Composants UI (SettingsDialog, etc.)
‚îÇ           ‚îú‚îÄ‚îÄ hooks/          # Custom hooks React
‚îÇ           ‚îú‚îÄ‚îÄ services/       # Appels API
‚îÇ           ‚îú‚îÄ‚îÄ contexts/       # Contextes React (Theme, etc.)
‚îÇ           ‚îî‚îÄ‚îÄ types/          # Types TypeScript
‚îú‚îÄ‚îÄ Config/
‚îÇ   ‚îî‚îÄ‚îÄ global.yaml             # Configuration centralis√©e
‚îú‚îÄ‚îÄ Doc/
‚îÇ   ‚îú‚îÄ‚îÄ sphinx/                 # Documentation g√©n√©r√©e
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md         # Ce fichier
‚îÇ   ‚îî‚îÄ‚îÄ SETUP.md                # Guide d'installation
‚îú‚îÄ‚îÄ Log/                        # Fichiers de logs
‚îú‚îÄ‚îÄ Test/                       # Tests automatis√©s (pytest)
‚îú‚îÄ‚îÄ .env                        # Variables d'environnement
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îî‚îÄ‚îÄ start.sh                    # Script de lancement tout-en-un
```

---

## Architecture Triple Agent

AutoLogic orchestre dynamiquement 3 agents sp√©cialis√©s pour un raisonnement robuste :

```mermaid
graph TD
    User[üë§ Utilisateur] --> Frontend[üíª Frontend React/Vite]
    Frontend --> API[üîå Backend FastAPI]
    
    subgraph "Core Engine - Triple Agent"
        API --> Factory[üè≠ Provider Factory]
        Factory --> Strategic[üß† Strategic Agent<br/>Planification]
        Factory --> Worker[üî® Worker Agent<br/>Ex√©cution]
        Factory --> Audit[‚öñÔ∏è Audit Agent<br/>Validation]
        
        Strategic --> Phases{8 Phases}
        Phases --> P0[0. Analyze]
        Phases --> P1[1. Select]
        Phases --> P2[2. Adapt]
        Phases --> P3[3. Structure]
        Phases --> P4[4. Verify]
        Phases --> P5[5. Execute]
        Phases --> P6[6. Critic H2]
        Phases --> P7[7. Synthesis/Audit]
    end
    
    Strategic <--> Modules[üìö 106 Modules<br/>Reasoning]
    Worker <--> VectorDB[(üóÑÔ∏è ChromaDB)]
    
    style User fill:#1e1e2e,stroke:#cdd6f4,color:#cdd6f4
    style Frontend fill:#1e1e2e,stroke:#89b4fa,color:#cdd6f4
    style API fill:#1e1e2e,stroke:#a6e3a1,color:#cdd6f4
    style Factory fill:#313244,stroke:#6c7086,color:#cdd6f4
    style Strategic fill:#1e1e2e,stroke:#f38ba8,color:#cdd6f4
    style Worker fill:#1e1e2e,stroke:#fab387,color:#cdd6f4
    style Audit fill:#1e1e2e,stroke:#cba6f7,color:#cdd6f4
```

### R√¥les des Agents

| Agent | R√¥le | LLM Recommand√© |
|-------|------|----------------|
| **Strategic (Root)** | Analyse, s√©lection, adaptation et structuration du plan | GPT-4, Gemini Pro, Claude 3 |
| **Worker** | Ex√©cution des √©tapes avec acc√®s au contexte RAG | GPT-4o-mini, Llama 3, Mistral |
| **Audit** | Validation qualit√©, critique H2, synth√®se finale | Mod√®le √©conomique ou gratuit |

---

## Provider Factory Pattern

Le syst√®me utilise un **Provider Factory** pour instancier dynamiquement les mod√®les LLM selon la configuration.

```mermaid
classDiagram
    class LLMProviderFactory {
        +create_llm(provider, model, **kwargs) BaseLLM
        +create_worker_llm(**kwargs) BaseLLM
        +create_audit_llm(**kwargs) BaseLLM
        +get_supported_providers() List
        +is_provider_enabled(provider) bool
    }

    class BaseLLM {
        <<abstract>>
        +call(prompt: str) str
        +model_name() str
        +provider_name() str
    }
    
    class OpenRouterLLM {
        -api_key: str
        +call(prompt: str) str
        +list_models_detailed() List
    }

    class ResilientCaller {
        -config: ResilienceConfig
        -rate_limiter: RateLimiter
        +call(func: Callable) Any
    }

    LLMProviderFactory ..> BaseLLM : Creates
    BaseLLM <|-- OpenRouterLLM
    BaseLLM <|-- OpenAILLM
    BaseLLM <|-- OllamaLLM
    BaseLLM <|-- VLlmLLM
    BaseLLM <|-- HuggingFaceLLM
    OpenRouterLLM ..> ResilientCaller : Uses
    OpenAILLM ..> ResilientCaller : Uses
```

---

## Couche de R√©silience

Chaque appel LLM est prot√©g√© par une couche de r√©silience universelle configurable :

1. **Rate Limiter** - Token bucket limitant les requ√™tes (d√©faut: 15 req/s)
2. **Retry Mechanism** - R√©essai automatique avec backoff exponentiel sur erreurs 429/5xx
3. **Fallback** - Bascule automatique vers mod√®le alternatif apr√®s X tentatives
4. **Timeout Adaptatif** - Gestion fine des d√©lais par provider et agent

```python
@dataclass
class ResilienceConfig:
    rate_limit: float = 15.0        # req/s
    retry_enabled: bool = True
    max_retries: int = 3
    retry_base_delay: float = 2.0   # secondes
    fallback_enabled: bool = True
```

---

## Cycle de Raisonnement (8 Phases)

Le moteur `AutoLogicEngine` orchestre un cycle complet assurant robustesse et qualit√© :

```mermaid
sequenceDiagram
    participant U as üë§ User
    participant S as üß† Strategic (Root)
    participant W as üî® Worker
    participant A as ‚öñÔ∏è Audit
    participant DB as üóÑÔ∏è Memory/RAG

    U->>S: 1. Nouvelle T√¢che
    Note over S: Phase 0: ANALYSE<br/>Extraction intention & contraintes
    
    rect rgb(30, 30, 46)
        Note right of S: Cycle Self-Discovery
        S->>S: Phase 1: SELECT (106 Modules)
        S->>S: Phase 2: ADAPT (Context)
        S->>S: Phase 3: STRUCTURE (Plan)
    end

    S->>A: Phase 4: VERIFY Plan
    
    alt Plan Invalid
        A-->>S: ‚ùå Reject (Feedback)
        S->>S: Restructure Plan (Loop)
    else Plan Valid
        A-->>W: ‚úÖ Approved
    end
    
    loop Phase 5: EXECUTE (Step-by-Step)
        W->>DB: Query Context
        DB-->>W: Relevant Chunks
        W->>W: Execute Step
        W->>A: Intermediate Result
    end

    Note over A: Phase 6: CRITIC H2<br/>Score < 0.8 ‚Üí Double-Backtrack

    W->>S: Execution Trace
    S->>A: Phase 7: SYNTHESIS Request
    
    loop Audit Loop (Time-boxed)
        A->>A: Validate Sufficiency
        alt Insuffisant
            A-->>S: Feedback
            S->>S: Refine
        end
    end
    
    A->>U: üèÅ R√©ponse Finale Audit√©e
```

### D√©tail des Phases

| Phase | Nom | Agent | Description |
|-------|-----|-------|-------------|
| 0 | **ANALYZE** | Strategic | Analyse intention utilisateur, extraction contraintes |
| 1 | **SELECT** | Strategic | S√©lection des modules parmi 106 disponibles |
| 2 | **ADAPT** | Strategic | Adaptation des descriptions au contexte |
| 3 | **STRUCTURE** | Strategic | G√©n√©ration du plan d'ex√©cution √©tape par √©tape |
| 4 | **VERIFY** | Audit | V√©rification logique et coh√©rence du plan |
| 5 | **EXECUTE** | Worker | Ex√©cution avec acc√®s RAG/contexte |
| 6 | **CRITIC (H2)** | Audit | √âvaluation qualit√© (score < 0.8 ‚Üí Double-Backtrack) |
| 7 | **SYNTHESIS** | Strategic + Audit | Compilation finale avec boucle d'audit it√©rative |

---

## Endpoints API

### Routers FastAPI

```mermaid
graph LR
    Client[Client HTTP] --> API[FastAPI App]
    
    API --> R1["/reason/*"]
    API --> R2["/api/*"]
    API --> R3["/, /health"]
    
    R1 --> E1[POST /reason/full]
    R1 --> E1b[POST /reason/full/stream]
    R1 --> E5[GET /reason/modules]
    
    R2 --> E2[GET /api/models]
    R2 --> E3[PUT /api/providers/config]
    R2 --> E4[POST /api/providers/verify]
    R2 --> E6[GET /api/providers/status]
    
    E1 --> Engine[AutoLogicEngine]
    Engine --> Phases[8 Phases + Audit Loop]
    E2 --> Registry[ModelRegistry]
```

### Table des Endpoints

| Route | M√©thode | Description |
|-------|---------|-------------|
| **Raisonnement** | | |
| `/reason/full` | POST | Cycle complet Self-Discover (synchrone) |
| `/reason/full/stream` | POST | Cycle complet avec progression SSE |
| `/reason/modules` | GET | Liste des 106 modules de raisonnement |
| **Configuration** | | |
| `/api/models` | GET | Providers et mod√®les disponibles |
| `/api/providers/config` | GET/PUT | Configuration active (Root, Worker, Audit) |
| `/api/providers/status` | GET | V√©rifie la disponibilit√© des providers |
| `/api/providers/{p}/models` | GET | Mod√®les d'un provider sp√©cifique |
| `/api/providers/verify` | POST | Teste une connexion API Key |
| **R√©silience** | | |
| `/api/resilience/{provider}` | GET | Config rate-limit/retry du provider |
| `/api/resilience` | PUT | Mise √† jour param√®tres r√©silience |
| **Syst√®me** | | |
| `/health` | GET | Status d√©taill√© du service |
| `/` | GET | Page d'accueil API |

---

## Architecture Frontend

### Stack Technique

| Technologie | Version | R√¥le |
|-------------|---------|------|
| **React** | 19 | Framework UI principal |
| **Vite** | 7 | Build tool & Dev server |
| **TailwindCSS** | 4 | Styling atomique |
| **Framer Motion** | 12 | Animations et transitions |
| **TypeScript** | 5.9 | Typage statique strict |

### Composants Cl√©s

L'interface est structur√©e autour du composant `AutoLogicInterface` :

- **SettingsDialog** - Modal de configuration dynamique
  - S√©lection Provider/Mod√®le (Root, Worker, Audit)
  - Gestion API Keys (stockage s√©curis√© local)
  - Param√®tres R√©silience par agent
  - Filtre "Free models only"
  
- **FlowVisualization** - Visualisation du cycle 8 phases
- **TaskInput** - Zone de saisie avec suggestions
- **PlanDisplay** - Affichage progressif des √©tapes
- **SolutionDisplay** - Rendu Markdown de la r√©ponse finale

### Design System: Glassmorphism / Liquid Glass

L'interface applique les standards design 2025 :

```css
/* Exemple de style Liquid Glass */
.glass-panel {
  background: rgba(255, 255, 255, 0.1);
  backdrop-filter: blur(20px);
  border: 1px solid rgba(255, 255, 255, 0.2);
  border-radius: 16px;
  box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
}
```

---

## Configuration

### global.yaml

Le fichier `Config/global.yaml` est la source de v√©rit√© pour les param√®tres par d√©faut. Il est charg√© au d√©marrage mais peut √™tre surcharg√© dynamiquement via l'API (en m√©moire).

```yaml
app:
  name: "AutoLogic"
  version: "0.3.0"

llm:
  active_provider: "openrouter"
  active_model: "google/gemini-2.0-flash-001"
  temperature: 0.5
  max_tokens: 2048
  
  # Configuration Worker & Audit agents
  worker_provider: "openrouter"
  worker_model: "openrouter/auto"
  audit_provider: "openrouter"
  audit_model: "qwen/qwen3-80b-a3b-instruct:free"
  
  resilience:
    rate_limit: 15.0
    retry_enabled: true
    max_retries: 3
    fallback_enabled: true
    
  providers:
    openrouter:
      enabled: true
      base_url: "https://openrouter.ai/api/v1"
    openai:
      enabled: true
    ollama:
      enabled: true
      auto_detect_models: true
    vllm:
      enabled: false
    huggingface:
      enabled: true
```

---

## Flux de Donn√©es

1. **User** configure le provider via `SettingsDialog` (Frontend)
2. **Frontend** envoie `PUT /api/providers/config` au Backend
3. **Backend** met √† jour le `ModelRegistry` en m√©moire
4. **User** lance une t√¢che
5. **Backend** (`reasoning.py`) demande LLMs au `ProviderFactory`
6. **Factory** cr√©e 3 LLMs configur√©s + Wrapper R√©silience
7. **Engine** ex√©cute le cycle Self-Discover 8 phases avec boucles de feedback
8. **Result** est stream√© (SSE) puis retourn√© au Frontend

---

*Documentation mise √† jour - Version 0.3.0 - F√©vrier 2026*
