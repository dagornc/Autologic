# Architecture du Projet AutoLogic

## Vue d'Ensemble

AutoLogic est un systÃ¨me d'agent IA implÃ©mentant le **Self-Discovery Reasoning Framework**. L'architecture est divisÃ©e en deux parties principales : un Backend Python (FastAPI) et un Frontend React.

---

## Arborescence du Projet

```
AutoLogic/
â”œâ”€â”€ Cmd/                        # Scripts shell standalone
â”‚   â””â”€â”€ *.sh                    # (start_backend.sh, etc.)
â”œâ”€â”€ Code/
â”‚   â”œâ”€â”€ Backend/
â”‚   â”‚   â”œâ”€â”€ Phase1-Ingestion/   # [Futur] Pipeline d'ingestion RAG
â”‚   â”‚   â””â”€â”€ Phase2-Inference/   # Logique de raisonnement
â”‚   â”‚       â””â”€â”€ 01_Reasoning/
â”‚   â”‚           â””â”€â”€ autologic/  # Package principal
â”‚   â”‚               â”œâ”€â”€ core/           # Moteur, LLM, modÃ¨les
â”‚   â”‚               â”œâ”€â”€ routers/        # Endpoints FastAPI
â”‚   â”‚               â””â”€â”€ utils/          # Logging, helpers
â”‚   â””â”€â”€ Frontend/               # Application React/Vite
â”‚       â””â”€â”€ src/
â”‚           â”œâ”€â”€ components/     # Composants UI
â”‚           â”œâ”€â”€ hooks/          # Custom hooks
â”‚           â”œâ”€â”€ services/       # Appels API
â”‚           â””â”€â”€ types/          # Types TypeScript
â”œâ”€â”€ Config/
â”‚   â””â”€â”€ global.yaml             # Configuration centralisÃ©e
â”œâ”€â”€ Doc/
â”‚   â”œâ”€â”€ sphinx/                 # Documentation gÃ©nÃ©rÃ©e
â”‚   â”œâ”€â”€ ARCHITECTURE.md         # Ce fichier
â”‚   â””â”€â”€ SETUP.md                # Guide d'installation
â”œâ”€â”€ Log/                        # Fichiers de logs
â”œâ”€â”€ Test/                       # Tests automatisÃ©s
â”œâ”€â”€ .env                        # Variables d'environnement
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â””â”€â”€ start.sh                    # Script de lancement
```

---

## Architecture Backend

### Module Core

Le cÅ“ur du systÃ¨me est le **AutoLogicEngine** qui orchestre le cycle Self-Discovery.

```mermaid
classDiagram
    class BaseLLM {
        <<abstract>>
        +call(prompt: str) str
    }
    
    class OpenRouterLLM {
        -api_key: str
        -model_name: str
        +call(prompt: str) str
    }
    
    class AutoLogicEngine {
        -root_model: BaseLLM
        -worker_model: BaseLLM
        -reasoning_modules: List~ReasoningModule~
        +select_modules(task: str) List
        +adapt_modules(modules, task) List
        +structure_reasoning(adapted, task) ReasoningPlan
        +execute_with_plan(task, plan) Result
        +run_full_cycle(task: str) Result
    }
    
    class ReasoningModule {
        +id: str
        +name: str
        +description: str
        +category: str
    }
    
    class ReasoningPlan {
        +steps: List~Step~
        +estimated_complexity: str
        +total_steps: int
    }
    
    BaseLLM <|-- OpenRouterLLM
    AutoLogicEngine --> BaseLLM
    AutoLogicEngine --> ReasoningModule
    AutoLogicEngine --> ReasoningPlan
```

### Les 4 Phases du Cycle Self-Discovery

```mermaid
flowchart TB
    subgraph Phase1["ðŸ” PHASE 1: SELECT"]
        A[TÃ¢che utilisateur] --> B[Analyse sÃ©mantique]
        B --> C[SÃ©lection parmi 39 modules]
        C --> D[Modules pertinents]
    end
    
    subgraph Phase2["ðŸ”§ PHASE 2: ADAPT"]
        D --> E[Contextualisation]
        E --> F[Modules adaptÃ©s au problÃ¨me]
    end
    
    subgraph Phase3["ðŸ“ PHASE 3: STRUCTURE"]
        F --> G[Ordonnancement logique]
        G --> H[Plan de raisonnement]
    end
    
    subgraph Phase4["âš¡ PHASE 4: EXECUTE"]
        H --> I[ExÃ©cution pas-Ã -pas]
        I --> J[SynthÃ¨se finale]
        J --> K[Solution]
    end
    
    style Phase1 fill:#1a1b26,stroke:#7aa2f7
    style Phase2 fill:#1a1b26,stroke:#9ece6a
    style Phase3 fill:#1a1b26,stroke:#bb9af7
    style Phase4 fill:#1a1b26,stroke:#f7768e
```

| Phase | ModÃ¨le | Description |
|-------|--------|-------------|
| **SELECT** | Root LLM | Analyse la tÃ¢che et sÃ©lectionne les modules pertinents |
| **ADAPT** | Root LLM | Transforme les modules gÃ©nÃ©riques en instructions spÃ©cifiques |
| **STRUCTURE** | Root LLM | Ordonne les modules en un plan de raisonnement cohÃ©rent |
| **EXECUTE** | Worker LLM | Suit le plan pour gÃ©nÃ©rer la solution finale |

### Routers FastAPI

```mermaid
graph LR
    Client[Client HTTP] --> API[FastAPI App]
    
    API --> R1["/reason/*"]
    API --> R2["/api/*"]
    API --> R3["/, /health"]
    
    R1 --> E1[POST /reason/full]
    R1 --> E2[GET /reason/modules]
    R2 --> E3[GET /api/models]
    
    E1 --> Engine[AutoLogicEngine]
    E2 --> Engine
    E3 --> Registry[ModelRegistry]
```

### Endpoints

| Route | MÃ©thode | Handler | Description |
|-------|---------|---------|-------------|
| `/` | GET | `root()` | Health check basique |
| `/health` | GET | `health_check()` | Status dÃ©taillÃ© |
| `/reason/full` | POST | `solve_task()` | Cycle complet Self-Discover |
| `/reason/modules` | GET | `list_modules()` | Liste des 39 modules |
| `/api/models` | GET | `list_models()` | Providers et modÃ¨les LLM |

---

## Architecture Frontend

### Composants

```mermaid
graph TB
    App[App.tsx] --> ALI[AutoLogicInterface]
    ALI --> TP[ThemeProvider]
    TP --> Content[AutoLogicContent]
    
    Content --> Header
    Content --> SettingsDialog
    Content --> TaskInput
    Content --> LoadingOverlay
    Content --> ErrorMessage
    Content --> Results[Results Section]
    
    Results --> PlanDisplay
    Results --> SolutionDisplay
    
    Content --> Hook[useAutoLogic Hook]
    Hook --> API[apiClient Service]
```

### Structure des Types

```typescript
// Types principaux
interface ReasoningPlan {
  steps: ReasoningPlanStep[];
  estimated_complexity: 'low' | 'medium' | 'high';
  total_steps: number;
}

interface AutoLogicResult {
  task: string;
  plan: ReasoningPlan;
  final_output: string;
}

interface LLMConfig {
  provider: string;
  model: string;
}
```

---

## Flux de DonnÃ©es Complet

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant F as Frontend
    participant B as Backend API
    participant E as AutoLogicEngine
    participant L as LLM Provider
    
    U->>F: Saisit une tÃ¢che
    F->>B: POST /reason/full {task, config}
    B->>E: run_full_cycle(task)
    
    Note over E: Phase 1: SELECT
    E->>L: Prompt sÃ©lection modules
    L-->>E: Modules sÃ©lectionnÃ©s
    
    Note over E: Phase 2: ADAPT
    E->>L: Prompt adaptation
    L-->>E: Modules adaptÃ©s
    
    Note over E: Phase 3: STRUCTURE
    E->>L: Prompt structuration
    L-->>E: Plan de raisonnement
    
    Note over E: Phase 4: EXECUTE
    E->>L: Prompt exÃ©cution avec plan
    L-->>E: Solution finale
    
    E-->>B: {task, plan, final_output}
    B-->>F: JSON Response
    F-->>U: Affiche plan + solution
```

---

## Configuration

### Variables d'Environnement

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `OPENROUTER_API_KEY` | ClÃ© API OpenRouter | - |
| `LOG_LEVEL` | Niveau de log (DEBUG, INFO, etc.) | `INFO` |
| `CORS_ORIGINS` | Origines CORS autorisÃ©es | `http://localhost:5173` |

### global.yaml

```yaml
app:
  name: "AutoLogic"
  version: "0.1.0"

llm:
  default_provider: "openrouter"
  default_model: "google/gemini-2.0-flash-exp:free"
  temperature: 0.7
  max_tokens: 4096

vector_store:
  provider: "chromadb"
  path: "./data/chroma"
```

---

## Bonnes Pratiques

### Backend
- **Typage strict** : Tous les modÃ¨les utilisent Pydantic
- **Async** : Endpoints asynchrones pour performance
- **Logging** : Logs structurÃ©s dans `Log/backend_app.log`
- **Injection de dÃ©pendances** : Via FastAPI `Depends()`

### Frontend
- **Composants atomiques** : UI modulaire et rÃ©utilisable
- **Custom hooks** : Logique mÃ©tier isolÃ©e (`useAutoLogic`)
- **Types TypeScript** : Typage strict partagÃ© avec le backend
- **Animations** : Framer Motion pour UX fluide
